{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T06:20:39.218011Z",
     "iopub.status.busy": "2021-08-29T06:20:39.217348Z",
     "iopub.status.idle": "2021-08-29T06:20:42.004979Z",
     "shell.execute_reply": "2021-08-29T06:20:42.003904Z",
     "shell.execute_reply.started": "2021-08-29T06:20:39.217906Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9ca5eeefdda6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apurv\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import catboost\n",
    "import xgboost\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.26.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.90'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightgbm.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5fd41e581849>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcal_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/m5-forecasting-accuracy/calendar.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprices_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/m5-forecasting-accuracy/sell_prices.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msales_df_wide\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/m5-forecasting-accuracy/sales_train_evaluation.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "cal_df = pd.read_csv('../input/m5-forecasting-accuracy/calendar.csv')\n",
    "prices_df = pd.read_csv('../input/m5-forecasting-accuracy/sell_prices.csv')\n",
    "sales_df_wide = pd.read_csv('../input/m5-forecasting-accuracy/sales_train_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sales_df_wide' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0c7740e27364>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#selecting a random data point for prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msales_df_wide\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sales_df_wide' is not defined"
     ]
    }
   ],
   "source": [
    "#selecting a random data point for prediction\n",
    "input = sales_df_wide.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_1(input):\n",
    "    #there are many NaN values in event_name and event_type fields\n",
    "    #Filling them with 'NoEvent' and 'None' resp\n",
    "    cal_df['event_name_1'].fillna('NoEvent',inplace=True)\n",
    "    cal_df['event_type_1'].fillna('None',inplace=True)\n",
    "    cal_df['event_name_2'].fillna('NoEvent',inplace=True)\n",
    "    cal_df['event_type_2'].fillna('None',inplace=True)\n",
    "    #dropping redundant columns and changing datatypes to reduce memory usage\n",
    "    cal_df.drop(['date','weekday'],axis=1,inplace=True)\n",
    "    cal_df['wm_yr_wk'] = cal_df.wm_yr_wk.astype('int16')\n",
    "    cal_df['d'] = cal_df.d.str[2:].astype('int16')\n",
    "    for col in ['wday','month','snap_CA','snap_TX','snap_WI']:\n",
    "        cal_df[col] = cal_df[col].astype('int8')\n",
    "    for col in ['event_name_1','event_type_1','event_name_2','event_type_2']:\n",
    "        cal_df[col] = cal_df[col].astype('category')\n",
    "        \n",
    "    # changing datatypes to reduce memory usage\n",
    "    prices_df['store_id'] = prices_df.store_id.astype('category')\n",
    "    prices_df['item_id'] = prices_df.item_id.astype('category')\n",
    "    prices_df['wm_yr_wk'] = prices_df.wm_yr_wk.astype('int16')\n",
    "    prices_df['sell_price'] = prices_df.sell_price.astype('float16')\n",
    "    \n",
    "    #converting the wide-form data frame to long-form so that columns from other 2 data frames can be merged\n",
    "    train_df = pd.melt(sales_df_wide,id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'],\\\n",
    "                   var_name='d',value_name='units_sold')\n",
    "    # changing datatypes to reduce memory usage\n",
    "    train_df['d'] = train_df.d.str[2:].astype('int16')\n",
    "    train_df['units_sold'] = train_df.units_sold.astype('int16')\n",
    "    for col in ['id','item_id','dept_id','cat_id','store_id','state_id']:\n",
    "        train_df[col] = train_df[col].astype('category') \n",
    "\n",
    "    #merging with 'cal_df'\n",
    "    train_df = pd.merge(train_df,cal_df,on='d',how='left')\n",
    "    #merging with 'prices_df'\n",
    "    train_df = pd.merge(train_df,prices_df,on=['item_id','store_id','wm_yr_wk'],how='left')\n",
    "\n",
    "    del cal_df,prices_df,sales_df_wide\n",
    "\n",
    "    #sell_price data is not available for many rows. \n",
    "    #For previous weeks filling this data by mean sell_prices for the item_id and store_id pair\n",
    "    train_df['sell_price'].fillna(train_df.groupby(['store_id','item_id'])['sell_price'].transform('mean'),inplace=True)\n",
    "\n",
    "    #calculating lag features and filling NA values with 0\n",
    "    for i in [7,14,21,28]:\n",
    "        train_df['lag_'+str(i)] = train_df.groupby('id')['units_sold'].transform(lambda x:x.shift(i))\n",
    "        train_df['lag_'+str(i)].fillna(0,inplace=True)\n",
    "\n",
    "    #ref:https://www.kaggle.com/kyakovlev/m5-lags-features\n",
    "    #rolling window mean features and filling NA values with 0\n",
    "    for i in [7,14]:\n",
    "        train_df['rolling_mean_'+str(i)] = train_df.groupby('id')['units_sold'].transform(lambda x:x.rolling(i).mean())\n",
    "        train_df['rolling_mean_'+str(i)].fillna(0,inplace=True)\n",
    "    #rolling window meadion features and filling NA values with 0\n",
    "    for i in [7,14]:\n",
    "        train_df['rolling_median_'+str(i)] = train_df.groupby('id')['units_sold'].transform(lambda x:x.rolling(i).median())\n",
    "        train_df['rolling_median_'+str(i)].fillna(0,inplace=True)\n",
    "\n",
    "    #dropping features 'wm_yr_wk' and 'year' as they are similar to 'd'\n",
    "    train_df.drop(['wm_yr_wk','year'],axis=1,inplace=True)\n",
    "\n",
    "    for i in ['lag_7','lag_14','lag_21','lag_28','rolling_mean_7','rolling_mean_14','rolling_median_7','rolling_median_14']:\n",
    "        train_df[i] = train_df[i].astype('float16')\n",
    "    \n",
    "    y = train_df.loc[train_df.d.isin(range(500,1914))]['units_sold']\n",
    "    y_test = train_df.loc[train_df.d.isin(range(1914,1942))]['units_sold']\n",
    "    train_df.drop(['units_sold'],axis=1,inplace=True)\n",
    "    x = train_df.loc[train_df.d.isin(range(500,1914))]\n",
    "    x_test = train_df.loc[train_df.d.isin(range(1914,1942))]\n",
    "    del train_df\n",
    "    x_train1,x_train2,y_train1,y_train2 = train_test_split(x,y,test_size=0.5,random_state=42)\n",
    "    del x,y\n",
    "\n",
    "    #feature encoding\n",
    "    le = LabelEncoder()\n",
    "    x_train1_item_cat = le.fit_transform(x_train1.item_id.values)\n",
    "    x_train2_item_cat = le.transform(x_train2.item_id.values)\n",
    "    x_test_item_cat = le.transform(x_test.item_id.values)\n",
    "\n",
    "    le_id = LabelEncoder()\n",
    "    x_train1_id_cat = le_id.fit_transform(x_train1.id.values)\n",
    "    x_train2_id_cat = le_id.transform(x_train2.id.values)\n",
    "    x_test_id_cat = le_id.transform(x_test.id.values)\n",
    "\n",
    "    x_train1_event_name_1 = le.fit_transform(x_train1.event_name_1.values)\n",
    "    x_train2_event_name_1 = le.transform(x_train2.event_name_1.values)\n",
    "    x_test_event_name_1 = le.transform(x_test.event_name_1.values)\n",
    "\n",
    "    x_train1_event_type_1 = le.fit_transform(x_train1.event_type_1.values)\n",
    "    x_train2_event_type_1 = le.transform(x_train2.event_type_1.values)\n",
    "    x_test_event_type_1 = le.transform(x_test.event_type_1.values)\n",
    "\n",
    "    x_train1_event_name_2 = le.fit_transform(x_train1.event_name_2.values)\n",
    "    x_train2_event_name_2 = le.transform(x_train2.event_name_2.values)\n",
    "    x_test_event_name_2 = le.transform(x_test.event_name_2.values)\n",
    "\n",
    "    x_train1_event_type_2 = le.fit_transform(x_train1.event_type_2.values)\n",
    "    x_train2_event_type_2 = le.transform(x_train2.event_type_2.values)\n",
    "    x_test_event_type_2 = le.transform(x_test.event_type_2.values)\n",
    "\n",
    "    x_train1['item_id'] = x_train1_item_cat\n",
    "    x_train2['item_id'] = x_train2_item_cat\n",
    "    x_test['item_id'] = x_test_item_cat\n",
    "\n",
    "    x_train1['id'] = x_train1_id_cat\n",
    "    x_train2['id'] = x_train2_id_cat\n",
    "    x_test['id'] = x_test_id_cat\n",
    "\n",
    "    x_train1['event_name_1'] = x_train1_event_name_1\n",
    "    x_train2['event_name_1'] = x_train2_event_name_1\n",
    "    x_test['event_name_1'] = x_test_event_name_1\n",
    "\n",
    "    x_train1['event_type_1'] = x_train1_event_type_1\n",
    "    x_train2['event_type_1'] = x_train2_event_type_1\n",
    "    x_test['event_type_1'] = x_test_event_type_1\n",
    "\n",
    "    x_train1['event_name_2'] = x_train1_event_name_2\n",
    "    x_train2['event_name_2'] = x_train2_event_name_2\n",
    "    x_test['event_name_2'] = x_test_event_name_2\n",
    "\n",
    "    x_train1['event_type_2'] = x_train1_event_type_2\n",
    "    x_train2['event_type_2'] = x_train2_event_type_2\n",
    "    x_test['event_type_2'] = x_test_event_type_2\n",
    "\n",
    "    del x_train1_item_cat,x_train1_id_cat,x_train1_event_name_1,x_train1_event_type_1,x_train1_event_name_2,x_train1_event_type_2\n",
    "    del x_train2_item_cat,x_train2_id_cat,x_train2_event_name_1,x_train2_event_type_1,x_train2_event_name_2,x_train2_event_type_2\n",
    "    del x_test_item_cat,x_test_id_cat,x_test_event_name_1,x_test_event_type_1,x_test_event_name_2,x_test_event_type_2\n",
    "\n",
    "    x_train1_dept_cat = le.fit_transform(x_train1.dept_id.values)\n",
    "    x_train2_dept_cat = le.transform(x_train2.dept_id.values)\n",
    "    x_test_dept_cat = le.transform(x_test.dept_id.values)\n",
    "\n",
    "    x_train1_cat = le.fit_transform(x_train1.cat_id.values)\n",
    "    x_train2_cat = le.transform(x_train2.cat_id.values)\n",
    "    x_test_cat = le.transform(x_test.cat_id.values)\n",
    "\n",
    "    x_train1_store_cat = le.fit_transform(x_train1.store_id.values)\n",
    "    x_train2_store_cat = le.transform(x_train2.store_id.values)\n",
    "    x_test_store_cat = le.transform(x_test.store_id.values)\n",
    "\n",
    "    x_train1_state_cat = le.fit_transform(x_train1.state_id.values)\n",
    "    x_train2_state_cat = le.transform(x_train2.state_id.values)\n",
    "    x_test_state_cat = le.transform(x_test.state_id.values)\n",
    "\n",
    "    x_train1['dept_id'] = x_train1_dept_cat\n",
    "    x_train2['dept_id'] = x_train2_dept_cat\n",
    "    x_test['dept_id'] = x_test_dept_cat\n",
    "\n",
    "    x_train1['cat_id'] = x_train1_cat\n",
    "    x_train2['cat_id'] = x_train2_cat\n",
    "    x_test['cat_id'] = x_test_cat\n",
    "\n",
    "    x_train1['store_id'] = x_train1_store_cat\n",
    "    x_train2['store_id'] = x_train2_store_cat\n",
    "    x_test['store_id'] = x_test_store_cat\n",
    "\n",
    "    x_train1['state_id'] = x_train1_state_cat\n",
    "    x_train2['state_id'] = x_train2_state_cat\n",
    "    x_test['state_id'] = x_test_state_cat\n",
    "\n",
    "    del x_train1_dept_cat,x_train1_cat,x_train1_store_cat,x_train1_state_cat\n",
    "    del x_train2_dept_cat,x_train2_cat,x_train2_store_cat,x_train2_state_cat\n",
    "    del x_test_dept_cat,x_test_cat,x_test_store_cat,x_test_state_cat\n",
    "\n",
    "    for i in ['item_id','event_name_1','event_type_1','event_name_2','event_type_2']:\n",
    "        x_train1[i] = x_train1[i].astype('int16')\n",
    "        x_train2[i] = x_train2[i].astype('int16')\n",
    "        x_test[i] = x_test[i].astype('int16')\n",
    "    \n",
    "    for i in ['dept_id','cat_id','store_id','state_id']:\n",
    "        x_train1[i] = x_train1[i].astype('int8')\n",
    "        x_train2[i] = x_train2[i].astype('int8')\n",
    "        x_test[i] = x_test[i].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T06:31:24.844302Z",
     "iopub.status.busy": "2021-08-29T06:31:24.844023Z",
     "iopub.status.idle": "2021-08-29T06:31:24.849930Z",
     "shell.execute_reply": "2021-08-29T06:31:24.848997Z",
     "shell.execute_reply.started": "2021-08-29T06:31:24.844274Z"
    }
   },
   "outputs": [],
   "source": [
    "#function to calculate assymmetric rmse,custom metric function\n",
    "def armse(y_act,y_pred):\n",
    "    score=0\n",
    "    n = len(y_act)\n",
    "    diff = np.array(y_pred) - np.array(y_act)\n",
    "    for ele in diff:\n",
    "        if ele<0:\n",
    "            score += 4*(ele**2)\n",
    "        else:\n",
    "            score += ele**2\n",
    "    return np.sqrt(score/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T06:31:24.851348Z",
     "iopub.status.busy": "2021-08-29T06:31:24.851099Z",
     "iopub.status.idle": "2021-08-29T06:35:25.079899Z",
     "shell.execute_reply": "2021-08-29T06:35:25.078845Z",
     "shell.execute_reply.started": "2021-08-29T06:31:24.851324Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=11,min_samples_split=3,random_state=0)\n",
    "dt.fit(x_train1,y_train1)\n",
    "y_pred2_dt = dt.predict(x_train2)\n",
    "y_test_dt = dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T06:35:25.081564Z",
     "iopub.status.busy": "2021-08-29T06:35:25.081254Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=64,max_depth=12,min_samples_split=6,random_state=0,n_jobs=-1)\n",
    "rf.fit(x_train1,y_train1)\n",
    "y_pred2_rf = rf.predict(x_train2)\n",
    "y_test_rf = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(learning_rate=0.140999404993131, max_depth=9, n_estimators=56,n_jobs=-1)\n",
    "xgb.fit(x_train1,y_train1)\n",
    "y_pred2_xgb = xgb.predict(x_train2)\n",
    "y_test_xgb = xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMRegressor(learning_rate=0.26661528358747144, max_depth=8, n_estimators=90, n_jobs=-1)\n",
    "lgbm.fit(x_train1,y_train1)\n",
    "y_pred2_lgbm = lgbm.predict(x_train2)\n",
    "y_test_lgbm = lgbm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostRegressor(learning_rate=0.55,depth=3,logging_level=\"Silent\")\n",
    "cat.fit(x_train1,y_train1)\n",
    "y_pred2_cat = cat.predict(x_train2)\n",
    "y_test_cat = cat.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_meta = np.vstack((y_pred2_dt,y_pred2_rf,y_pred2_xgb,y_pred2_lgbm,y_pred2_cat)).T\n",
    "x_test_meta = np.vstack((y_test_dt,y_test_rf,y_test_xgb,y_test_lgbm,y_test_cat)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Linear Regression metamodel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(n_jobs=-1)\n",
    "lr.fit(x_train_meta,y_train2)\n",
    "y_train_meta = lr.predict(x_train_meta)\n",
    "y_test_meta = lr.predict(x_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'id':le_id.inverse_transform(x_test['id'].values),'d':x_test['d'].values,'units':y_test_meta}\n",
    "dt_cv = pd.DataFrame(data=d)\n",
    "dt_cv = dt_cv.pivot_table(index='id',columns='d',values='units').reset_index()\n",
    "names = {1914:'F1',1915:'F2',1916:'F3',1917:'F4',1918:'F5',1919:'F6',1920:'F7',1921:'F8',1922:'F9',1923:'F10',1924:'F11',1925:'F12',1926:'F13',1927:'F14',1928:'F15',1929:'F16',1930:'F17',1931:'F18',1932:'F19',1933:'F20',1934:'F21',1935:'F22',1936:'F23',1937:'F24',1938:'F25',1939:'F26',1940:'F27',1941:'F28'}\n",
    "dt_cv.rename(columns=names,inplace=True)\n",
    "dt_test = dt_cv.copy()\n",
    "dt_cv['id'] = dt_cv.apply(lambda x: x['id'].replace('evaluation','validation'),axis=1)\n",
    "dt_sub = pd.concat([dt_cv,dt_test],axis=0)\n",
    "dt_sub.to_csv('customstackinglr.csv',index=False)\n",
    "del dt_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = mse(y_train2,y_train_meta,squared=False)\n",
    "armse_train = armse(y_train2,y_train_meta)\n",
    "rmse_test = mse(y_test,y_test_meta,squared=False)\n",
    "armse_test = armse(y_test,y_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train: RMSE {} ARMSE {}'.format(rmse_train,armse_train))\n",
    "print('Test: RMSE {} ARMSE {}'.format(rmse_test,armse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_2():\n",
    "    #there are many NaN values in event_name and event_type fields\n",
    "    #Filling them with 'NoEvent' and 'None' resp\n",
    "    cal_df['event_name_1'].fillna('NoEvent',inplace=True)\n",
    "    cal_df['event_type_1'].fillna('None',inplace=True)\n",
    "    cal_df['event_name_2'].fillna('NoEvent',inplace=True)\n",
    "    cal_df['event_type_2'].fillna('None',inplace=True)\n",
    "    #dropping redundant columns and changing datatypes to reduce memory usage\n",
    "    cal_df.drop(['date','weekday'],axis=1,inplace=True)\n",
    "    cal_df['wm_yr_wk'] = cal_df.wm_yr_wk.astype('int16')\n",
    "    cal_df['d'] = cal_df.d.str[2:].astype('int16')\n",
    "    for col in ['wday','month','snap_CA','snap_TX','snap_WI']:\n",
    "        cal_df[col] = cal_df[col].astype('int8')\n",
    "    for col in ['event_name_1','event_type_1','event_name_2','event_type_2']:\n",
    "        cal_df[col] = cal_df[col].astype('category')\n",
    "        \n",
    "    # changing datatypes to reduce memory usage\n",
    "    prices_df['store_id'] = prices_df.store_id.astype('category')\n",
    "    prices_df['item_id'] = prices_df.item_id.astype('category')\n",
    "    prices_df['wm_yr_wk'] = prices_df.wm_yr_wk.astype('int16')\n",
    "    prices_df['sell_price'] = prices_df.sell_price.astype('float16')\n",
    "    \n",
    "    #converting the wide-form data frame to long-form so that columns from other 2 data frames can be merged\n",
    "    train_df = pd.melt(sales_df_wide,id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'],\\\n",
    "                   var_name='d',value_name='units_sold')\n",
    "    # changing datatypes to reduce memory usage\n",
    "    train_df['d'] = train_df.d.str[2:].astype('int16')\n",
    "    train_df['units_sold'] = train_df.units_sold.astype('int16')\n",
    "    for col in ['id','item_id','dept_id','cat_id','store_id','state_id']:\n",
    "        train_df[col] = train_df[col].astype('category') \n",
    "\n",
    "    #merging with 'cal_df'\n",
    "    train_df = pd.merge(train_df,cal_df,on='d',how='left')\n",
    "    #merging with 'prices_df'\n",
    "    train_df = pd.merge(train_df,prices_df,on=['item_id','store_id','wm_yr_wk'],how='left')\n",
    "\n",
    "    del cal_df,prices_df,sales_df_wide\n",
    "\n",
    "    #sell_price data is not available for many rows. \n",
    "    #For previous weeks filling this data by mean sell_prices for the item_id and store_id pair\n",
    "    train_df['sell_price'].fillna(train_df.groupby(['store_id','item_id'])['sell_price'].transform('mean'),inplace=True)\n",
    "\n",
    "    #calculating lag features and filling NA values with 0\n",
    "    for i in [7,14,21,28]:\n",
    "        train_df['lag_'+str(i)] = train_df.groupby('id')['units_sold'].transform(lambda x:x.shift(i))\n",
    "        train_df['lag_'+str(i)].fillna(0,inplace=True)\n",
    "\n",
    "    #ref:https://www.kaggle.com/kyakovlev/m5-lags-features\n",
    "    #rolling window mean features and filling NA values with 0\n",
    "    for i in [7,14]:\n",
    "        train_df['rolling_mean_'+str(i)] = train_df.groupby('id')['units_sold'].transform(lambda x:x.rolling(i).mean())\n",
    "        train_df['rolling_mean_'+str(i)].fillna(0,inplace=True)\n",
    "    #rolling window meadion features and filling NA values with 0\n",
    "    for i in [7,14]:\n",
    "        train_df['rolling_median_'+str(i)] = train_df.groupby('id')['units_sold'].transform(lambda x:x.rolling(i).median())\n",
    "        train_df['rolling_median_'+str(i)].fillna(0,inplace=True)\n",
    "\n",
    "    #dropping features 'wm_yr_wk' and 'year' as they are similar to 'd'\n",
    "    train_df.drop(['wm_yr_wk','year'],axis=1,inplace=True)\n",
    "\n",
    "    for i in ['lag_7','lag_14','lag_21','lag_28','rolling_mean_7','rolling_mean_14','rolling_median_7','rolling_median_14']:\n",
    "        train_df[i] = train_df[i].astype('float16')\n",
    "    \n",
    "    y = train_df.loc[train_df.d.isin(range(500,1914))]['units_sold']\n",
    "    y_test = train_df.loc[train_df.d.isin(range(1914,1942))]['units_sold']\n",
    "    train_df.drop(['units_sold'],axis=1,inplace=True)\n",
    "    x = train_df.loc[train_df.d.isin(range(500,1914))]\n",
    "    x_test = train_df.loc[train_df.d.isin(range(1914,1942))]\n",
    "    del train_df\n",
    "    x_train1,x_train2,y_train1,y_train2 = train_test_split(x,y,test_size=0.5,random_state=42)\n",
    "    del x,y\n",
    "\n",
    "    #feature encoding\n",
    "    le = LabelEncoder()\n",
    "    x_train1_item_cat = le.fit_transform(x_train1.item_id.values)\n",
    "    x_train2_item_cat = le.transform(x_train2.item_id.values)\n",
    "    x_test_item_cat = le.transform(x_test.item_id.values)\n",
    "\n",
    "    le_id = LabelEncoder()\n",
    "    x_train1_id_cat = le_id.fit_transform(x_train1.id.values)\n",
    "    x_train2_id_cat = le_id.transform(x_train2.id.values)\n",
    "    x_test_id_cat = le_id.transform(x_test.id.values)\n",
    "\n",
    "    x_train1_event_name_1 = le.fit_transform(x_train1.event_name_1.values)\n",
    "    x_train2_event_name_1 = le.transform(x_train2.event_name_1.values)\n",
    "    x_test_event_name_1 = le.transform(x_test.event_name_1.values)\n",
    "\n",
    "    x_train1_event_type_1 = le.fit_transform(x_train1.event_type_1.values)\n",
    "    x_train2_event_type_1 = le.transform(x_train2.event_type_1.values)\n",
    "    x_test_event_type_1 = le.transform(x_test.event_type_1.values)\n",
    "\n",
    "    x_train1_event_name_2 = le.fit_transform(x_train1.event_name_2.values)\n",
    "    x_train2_event_name_2 = le.transform(x_train2.event_name_2.values)\n",
    "    x_test_event_name_2 = le.transform(x_test.event_name_2.values)\n",
    "\n",
    "    x_train1_event_type_2 = le.fit_transform(x_train1.event_type_2.values)\n",
    "    x_train2_event_type_2 = le.transform(x_train2.event_type_2.values)\n",
    "    x_test_event_type_2 = le.transform(x_test.event_type_2.values)\n",
    "\n",
    "    x_train1['item_id'] = x_train1_item_cat\n",
    "    x_train2['item_id'] = x_train2_item_cat\n",
    "    x_test['item_id'] = x_test_item_cat\n",
    "\n",
    "    x_train1['id'] = x_train1_id_cat\n",
    "    x_train2['id'] = x_train2_id_cat\n",
    "    x_test['id'] = x_test_id_cat\n",
    "\n",
    "    x_train1['event_name_1'] = x_train1_event_name_1\n",
    "    x_train2['event_name_1'] = x_train2_event_name_1\n",
    "    x_test['event_name_1'] = x_test_event_name_1\n",
    "\n",
    "    x_train1['event_type_1'] = x_train1_event_type_1\n",
    "    x_train2['event_type_1'] = x_train2_event_type_1\n",
    "    x_test['event_type_1'] = x_test_event_type_1\n",
    "\n",
    "    x_train1['event_name_2'] = x_train1_event_name_2\n",
    "    x_train2['event_name_2'] = x_train2_event_name_2\n",
    "    x_test['event_name_2'] = x_test_event_name_2\n",
    "\n",
    "    x_train1['event_type_2'] = x_train1_event_type_2\n",
    "    x_train2['event_type_2'] = x_train2_event_type_2\n",
    "    x_test['event_type_2'] = x_test_event_type_2\n",
    "\n",
    "    del x_train1_item_cat,x_train1_id_cat,x_train1_event_name_1,x_train1_event_type_1,x_train1_event_name_2,x_train1_event_type_2\n",
    "    del x_train2_item_cat,x_train2_id_cat,x_train2_event_name_1,x_train2_event_type_1,x_train2_event_name_2,x_train2_event_type_2\n",
    "    del x_test_item_cat,x_test_id_cat,x_test_event_name_1,x_test_event_type_1,x_test_event_name_2,x_test_event_type_2\n",
    "\n",
    "    x_train1_dept_cat = le.fit_transform(x_train1.dept_id.values)\n",
    "    x_train2_dept_cat = le.transform(x_train2.dept_id.values)\n",
    "    x_test_dept_cat = le.transform(x_test.dept_id.values)\n",
    "\n",
    "    x_train1_cat = le.fit_transform(x_train1.cat_id.values)\n",
    "    x_train2_cat = le.transform(x_train2.cat_id.values)\n",
    "    x_test_cat = le.transform(x_test.cat_id.values)\n",
    "\n",
    "    x_train1_store_cat = le.fit_transform(x_train1.store_id.values)\n",
    "    x_train2_store_cat = le.transform(x_train2.store_id.values)\n",
    "    x_test_store_cat = le.transform(x_test.store_id.values)\n",
    "\n",
    "    x_train1_state_cat = le.fit_transform(x_train1.state_id.values)\n",
    "    x_train2_state_cat = le.transform(x_train2.state_id.values)\n",
    "    x_test_state_cat = le.transform(x_test.state_id.values)\n",
    "\n",
    "    x_train1['dept_id'] = x_train1_dept_cat\n",
    "    x_train2['dept_id'] = x_train2_dept_cat\n",
    "    x_test['dept_id'] = x_test_dept_cat\n",
    "\n",
    "    x_train1['cat_id'] = x_train1_cat\n",
    "    x_train2['cat_id'] = x_train2_cat\n",
    "    x_test['cat_id'] = x_test_cat\n",
    "\n",
    "    x_train1['store_id'] = x_train1_store_cat\n",
    "    x_train2['store_id'] = x_train2_store_cat\n",
    "    x_test['store_id'] = x_test_store_cat\n",
    "\n",
    "    x_train1['state_id'] = x_train1_state_cat\n",
    "    x_train2['state_id'] = x_train2_state_cat\n",
    "    x_test['state_id'] = x_test_state_cat\n",
    "\n",
    "    del x_train1_dept_cat,x_train1_cat,x_train1_store_cat,x_train1_state_cat\n",
    "    del x_train2_dept_cat,x_train2_cat,x_train2_store_cat,x_train2_state_cat\n",
    "    del x_test_dept_cat,x_test_cat,x_test_store_cat,x_test_state_cat\n",
    "\n",
    "    for i in ['item_id','event_name_1','event_type_1','event_name_2','event_type_2']:\n",
    "        x_train1[i] = x_train1[i].astype('int16')\n",
    "        x_train2[i] = x_train2[i].astype('int16')\n",
    "        x_test[i] = x_test[i].astype('int16')\n",
    "    \n",
    "    for i in ['dept_id','cat_id','store_id','state_id']:\n",
    "        x_train1[i] = x_train1[i].astype('int8')\n",
    "        x_train2[i] = x_train2[i].astype('int8')\n",
    "        x_test[i] = x_test[i].astype('int8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
